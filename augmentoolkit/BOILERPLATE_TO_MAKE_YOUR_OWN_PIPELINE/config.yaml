API:
  API_KEY_A: key
  API_KEY_B: ToIaiNGFuJ1wLNjlt8DBhMejhLJhx30ZVKVVTVQ5kLGP3YQY
  BASE_URL_A: https://api.together.xyz
  BASE_URL_B: https://api.fireworks.ai/inference/v1
  LOGICAL_MODEL_A: meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo
  LOGICAL_MODEL_B: accounts/fireworks/models/llama-v3p1-8b-instruct
  MODE_A: api
  MODE_B: api
PATH:
  DEFAULT_PROMPTS: ./prompts
  INPUT: ./raw_txt_input
  OUTPUT: ./output
  PROMPTS: ./prompts
PHASES:
  PHASE_INDEX: 2
  WORK_IN_PHASES: True
SYSTEM:
  COMPLETION_MODE: False
  CONCURRENCY_LIMIT: 3
  STOP: True
  SUBSET_SIZE: 3
  USE_MIN_P: False
  USE_SUBSET: True # you will probably want to have use_subset on during testing and development to save money.
  CHUNK_SIZE: 2000
