{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 04:59:49,772 - INFO - Successfully loaded 50 questions from CSV\n",
      "2024-11-06 04:59:49,774 - INFO - Starting evaluation for model: hf.co/bartowski/Phi-3-medium-128k-instruct-GGUF:Q3_K_S\n",
      "2024-11-06 04:59:59,775 - INFO - Started model: hf.co/bartowski/Phi-3-medium-128k-instruct-GGUF:Q3_K_S\n",
      "2024-11-06 04:59:59,778 - INFO - Processing Question 1\n",
      "2024-11-06 05:00:05,826 - INFO - Processing Question 2\n",
      "2024-11-06 05:00:08,975 - INFO - Processing Question 3\n",
      "2024-11-06 05:00:12,779 - INFO - Processing Question 4\n",
      "2024-11-06 05:00:17,011 - INFO - Processing Question 5\n",
      "2024-11-06 05:00:22,223 - INFO - Processing Question 6\n",
      "2024-11-06 05:00:26,055 - INFO - Processing Question 7\n",
      "2024-11-06 05:00:29,151 - INFO - Processing Question 8\n",
      "2024-11-06 05:00:32,479 - INFO - Processing Question 9\n",
      "2024-11-06 05:00:35,615 - INFO - Processing Question 10\n",
      "2024-11-06 05:00:40,771 - INFO - Processing Question 11\n",
      "2024-11-06 05:00:47,783 - INFO - Processing Question 12\n",
      "2024-11-06 05:00:54,251 - INFO - Processing Question 13\n",
      "2024-11-06 05:00:58,563 - INFO - Processing Question 14\n",
      "2024-11-06 05:01:01,751 - INFO - Processing Question 15\n",
      "2024-11-06 05:01:04,987 - INFO - Processing Question 16\n",
      "2024-11-06 05:01:12,408 - INFO - Processing Question 17\n",
      "2024-11-06 05:01:19,104 - INFO - Processing Question 18\n",
      "2024-11-06 05:01:22,063 - INFO - Processing Question 19\n",
      "2024-11-06 05:01:25,844 - INFO - Processing Question 20\n",
      "2024-11-06 05:01:28,976 - INFO - Processing Question 21\n",
      "2024-11-06 05:01:35,531 - INFO - Processing Question 22\n",
      "2024-11-06 05:01:41,744 - INFO - Processing Question 23\n",
      "2024-11-06 05:01:45,852 - INFO - Processing Question 24\n",
      "2024-11-06 05:01:50,327 - INFO - Processing Question 25\n",
      "2024-11-06 05:01:58,583 - INFO - Processing Question 26\n",
      "2024-11-06 05:02:06,632 - INFO - Processing Question 27\n",
      "2024-11-06 05:02:10,080 - INFO - Processing Question 28\n",
      "2024-11-06 05:02:17,783 - INFO - Processing Question 29\n",
      "2024-11-06 05:02:20,987 - INFO - Processing Question 30\n",
      "2024-11-06 05:02:25,643 - INFO - Processing Question 31\n",
      "2024-11-06 05:02:35,371 - INFO - Processing Question 32\n",
      "2024-11-06 05:02:43,088 - INFO - Processing Question 33\n",
      "2024-11-06 05:02:46,884 - INFO - Processing Question 34\n",
      "2024-11-06 05:02:53,980 - INFO - Processing Question 35\n",
      "2024-11-06 05:03:00,688 - INFO - Processing Question 36\n",
      "2024-11-06 05:03:04,788 - INFO - Processing Question 37\n",
      "2024-11-06 05:03:12,148 - INFO - Processing Question 38\n",
      "2024-11-06 05:03:15,400 - INFO - Processing Question 39\n",
      "2024-11-06 05:03:23,068 - INFO - Processing Question 40\n",
      "2024-11-06 05:03:29,520 - INFO - Processing Question 41\n",
      "2024-11-06 05:03:43,032 - INFO - Processing Question 42\n",
      "2024-11-06 05:03:52,361 - INFO - Processing Question 43\n",
      "2024-11-06 05:03:56,856 - INFO - Processing Question 44\n",
      "2024-11-06 05:04:03,876 - INFO - Processing Question 45\n",
      "2024-11-06 05:04:12,228 - INFO - Processing Question 46\n",
      "2024-11-06 05:04:17,352 - INFO - Processing Question 47\n",
      "2024-11-06 05:04:21,472 - INFO - Processing Question 48\n",
      "2024-11-06 05:04:27,964 - INFO - Processing Question 49\n",
      "2024-11-06 05:04:32,041 - INFO - Processing Question 50\n",
      "2024-11-06 05:04:38,570 - INFO - Stopped Ollama model\n",
      "2024-11-06 05:04:43,571 - INFO - Starting evaluation for model: hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q4_K_M\n",
      "2024-11-06 05:04:53,574 - INFO - Started model: hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q4_K_M\n",
      "2024-11-06 05:04:53,575 - INFO - Processing Question 1\n",
      "2024-11-06 05:05:01,491 - INFO - Processing Question 2\n",
      "2024-11-06 05:05:04,804 - INFO - Processing Question 3\n",
      "2024-11-06 05:05:10,900 - INFO - Processing Question 4\n",
      "2024-11-06 05:05:15,940 - INFO - Processing Question 5\n",
      "2024-11-06 05:05:21,136 - INFO - Processing Question 6\n",
      "2024-11-06 05:05:24,869 - INFO - Processing Question 7\n",
      "2024-11-06 05:05:29,641 - INFO - Processing Question 8\n",
      "2024-11-06 05:05:33,097 - INFO - Processing Question 9\n",
      "2024-11-06 05:05:37,039 - INFO - Processing Question 10\n",
      "2024-11-06 05:05:42,161 - INFO - Processing Question 11\n",
      "2024-11-06 05:05:47,540 - INFO - Processing Question 12\n",
      "2024-11-06 05:05:53,348 - INFO - Processing Question 13\n",
      "2024-11-06 05:05:57,048 - INFO - Processing Question 14\n",
      "2024-11-06 05:06:01,829 - INFO - Processing Question 15\n",
      "2024-11-06 05:06:06,485 - INFO - Processing Question 16\n",
      "2024-11-06 05:06:11,698 - INFO - Processing Question 17\n",
      "2024-11-06 05:06:16,221 - INFO - Processing Question 18\n",
      "2024-11-06 05:06:19,797 - INFO - Processing Question 19\n",
      "2024-11-06 05:06:24,232 - INFO - Processing Question 20\n",
      "2024-11-06 05:06:28,361 - INFO - Processing Question 21\n",
      "2024-11-06 05:06:33,918 - INFO - Processing Question 22\n",
      "2024-11-06 05:06:41,221 - INFO - Processing Question 23\n",
      "2024-11-06 05:06:46,297 - INFO - Processing Question 24\n",
      "2024-11-06 05:06:53,053 - INFO - Processing Question 25\n",
      "2024-11-06 05:06:58,841 - INFO - Processing Question 26\n",
      "2024-11-06 05:07:05,460 - INFO - Processing Question 27\n",
      "2024-11-06 05:07:09,800 - INFO - Processing Question 28\n",
      "2024-11-06 05:07:15,128 - INFO - Processing Question 29\n",
      "2024-11-06 05:07:19,917 - INFO - Processing Question 30\n",
      "2024-11-06 05:07:24,576 - INFO - Processing Question 31\n",
      "2024-11-06 05:07:33,766 - INFO - Processing Question 32\n",
      "2024-11-06 05:07:42,136 - INFO - Processing Question 33\n",
      "2024-11-06 05:07:48,480 - INFO - Processing Question 34\n",
      "2024-11-06 05:07:54,813 - INFO - Processing Question 35\n",
      "2024-11-06 05:08:01,101 - INFO - Processing Question 36\n",
      "2024-11-06 05:08:07,312 - INFO - Processing Question 37\n",
      "2024-11-06 05:08:16,262 - INFO - Processing Question 38\n",
      "2024-11-06 05:08:21,953 - INFO - Processing Question 39\n",
      "2024-11-06 05:08:31,401 - INFO - Processing Question 40\n",
      "2024-11-06 05:08:39,625 - INFO - Processing Question 41\n",
      "2024-11-06 05:08:48,138 - INFO - Processing Question 42\n",
      "2024-11-06 05:08:56,289 - INFO - Processing Question 43\n",
      "2024-11-06 05:09:04,849 - INFO - Processing Question 44\n",
      "2024-11-06 05:09:13,385 - INFO - Processing Question 45\n",
      "2024-11-06 05:09:22,517 - INFO - Processing Question 46\n",
      "2024-11-06 05:09:31,761 - INFO - Processing Question 47\n",
      "2024-11-06 05:09:38,909 - INFO - Processing Question 48\n",
      "2024-11-06 05:09:48,290 - INFO - Processing Question 49\n",
      "2024-11-06 05:09:55,885 - INFO - Processing Question 50\n",
      "2024-11-06 05:10:06,421 - INFO - Stopped Ollama model\n",
      "2024-11-06 05:10:11,422 - INFO - Starting evaluation for model: hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16\n",
      "2024-11-06 05:10:21,424 - INFO - Started model: hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16\n",
      "2024-11-06 05:10:21,425 - INFO - Processing Question 1\n",
      "2024-11-06 05:10:21,427 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:10:23,432 - INFO - Processing Question 2\n",
      "2024-11-06 05:10:23,434 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:10:25,439 - INFO - Processing Question 3\n",
      "2024-11-06 05:10:25,442 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:10:27,446 - INFO - Processing Question 4\n",
      "2024-11-06 05:10:27,448 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:10:29,453 - INFO - Processing Question 5\n",
      "2024-11-06 05:10:29,455 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:10:31,460 - INFO - Processing Question 6\n",
      "2024-11-06 05:10:31,463 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:10:33,467 - INFO - Processing Question 7\n",
      "2024-11-06 05:10:33,470 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:10:35,475 - INFO - Processing Question 8\n",
      "2024-11-06 05:10:35,478 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:10:37,483 - INFO - Processing Question 9\n",
      "2024-11-06 05:10:37,487 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:10:39,493 - INFO - Processing Question 10\n",
      "2024-11-06 05:10:39,496 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:10:41,501 - INFO - Processing Question 11\n",
      "2024-11-06 05:10:41,504 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:10:43,509 - INFO - Processing Question 12\n",
      "2024-11-06 05:10:43,512 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:10:45,516 - INFO - Processing Question 13\n",
      "2024-11-06 05:10:45,519 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:10:47,524 - INFO - Processing Question 14\n",
      "2024-11-06 05:10:47,527 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:10:49,532 - INFO - Processing Question 15\n",
      "2024-11-06 05:10:49,535 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:10:51,540 - INFO - Processing Question 16\n",
      "2024-11-06 05:10:51,543 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:10:53,548 - INFO - Processing Question 17\n",
      "2024-11-06 05:10:53,551 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:10:55,556 - INFO - Processing Question 18\n",
      "2024-11-06 05:10:55,558 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:10:57,563 - INFO - Processing Question 19\n",
      "2024-11-06 05:10:57,565 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:10:59,570 - INFO - Processing Question 20\n",
      "2024-11-06 05:10:59,572 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:11:01,577 - INFO - Processing Question 21\n",
      "2024-11-06 05:11:01,579 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:11:03,584 - INFO - Processing Question 22\n",
      "2024-11-06 05:11:03,586 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:11:05,591 - INFO - Processing Question 23\n",
      "2024-11-06 05:11:05,594 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:11:07,600 - INFO - Processing Question 24\n",
      "2024-11-06 05:11:07,602 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:11:09,607 - INFO - Processing Question 25\n",
      "2024-11-06 05:11:09,611 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:11:11,616 - INFO - Processing Question 26\n",
      "2024-11-06 05:11:11,620 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:11:13,625 - INFO - Processing Question 27\n",
      "2024-11-06 05:11:13,628 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:11:15,635 - INFO - Processing Question 28\n",
      "2024-11-06 05:11:15,642 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:11:17,648 - INFO - Processing Question 29\n",
      "2024-11-06 05:11:17,651 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:11:19,659 - INFO - Processing Question 30\n",
      "2024-11-06 05:11:19,664 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:11:21,670 - INFO - Processing Question 31\n",
      "2024-11-06 05:11:21,673 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:11:23,678 - INFO - Processing Question 32\n",
      "2024-11-06 05:11:23,683 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:11:25,688 - INFO - Processing Question 33\n",
      "2024-11-06 05:11:25,691 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:11:27,696 - INFO - Processing Question 34\n",
      "2024-11-06 05:11:27,699 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:11:29,705 - INFO - Processing Question 35\n",
      "2024-11-06 05:11:29,708 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:11:31,713 - INFO - Processing Question 36\n",
      "2024-11-06 05:11:31,717 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:11:33,722 - INFO - Processing Question 37\n",
      "2024-11-06 05:11:33,725 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:11:35,731 - INFO - Processing Question 38\n",
      "2024-11-06 05:11:35,734 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:11:37,739 - INFO - Processing Question 39\n",
      "2024-11-06 05:11:37,743 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:11:39,748 - INFO - Processing Question 40\n",
      "2024-11-06 05:11:39,752 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:11:41,757 - INFO - Processing Question 41\n",
      "2024-11-06 05:11:41,759 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:11:43,765 - INFO - Processing Question 42\n",
      "2024-11-06 05:11:43,767 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:11:45,772 - INFO - Processing Question 43\n",
      "2024-11-06 05:11:45,775 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:11:47,780 - INFO - Processing Question 44\n",
      "2024-11-06 05:11:47,784 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:11:49,790 - INFO - Processing Question 45\n",
      "2024-11-06 05:11:49,793 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:11:51,800 - INFO - Processing Question 46\n",
      "2024-11-06 05:11:51,803 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:11:53,808 - INFO - Processing Question 47\n",
      "2024-11-06 05:11:53,811 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:11:55,816 - INFO - Processing Question 48\n",
      "2024-11-06 05:11:55,819 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:11:57,824 - INFO - Processing Question 49\n",
      "2024-11-06 05:11:57,827 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:11:59,832 - INFO - Processing Question 50\n",
      "2024-11-06 05:11:59,835 - ERROR - Error querying model hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:12:01,842 - INFO - Stopped Ollama model\n",
      "2024-11-06 05:12:06,843 - INFO - Starting evaluation for model: hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0\n",
      "2024-11-06 05:12:16,846 - INFO - Started model: hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0\n",
      "2024-11-06 05:12:16,847 - INFO - Processing Question 1\n",
      "2024-11-06 05:12:16,850 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:12:18,855 - INFO - Processing Question 2\n",
      "2024-11-06 05:12:18,858 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:12:20,864 - INFO - Processing Question 3\n",
      "2024-11-06 05:12:20,867 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:12:22,873 - INFO - Processing Question 4\n",
      "2024-11-06 05:12:22,876 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:12:24,881 - INFO - Processing Question 5\n",
      "2024-11-06 05:12:24,885 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:12:26,891 - INFO - Processing Question 6\n",
      "2024-11-06 05:12:26,894 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:12:28,899 - INFO - Processing Question 7\n",
      "2024-11-06 05:12:28,902 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:12:30,908 - INFO - Processing Question 8\n",
      "2024-11-06 05:12:30,910 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:12:32,916 - INFO - Processing Question 9\n",
      "2024-11-06 05:12:32,918 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:12:34,924 - INFO - Processing Question 10\n",
      "2024-11-06 05:12:34,927 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:12:36,932 - INFO - Processing Question 11\n",
      "2024-11-06 05:12:36,936 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:12:38,941 - INFO - Processing Question 12\n",
      "2024-11-06 05:12:38,945 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:12:40,950 - INFO - Processing Question 13\n",
      "2024-11-06 05:12:40,953 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:12:42,958 - INFO - Processing Question 14\n",
      "2024-11-06 05:12:42,961 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:12:44,967 - INFO - Processing Question 15\n",
      "2024-11-06 05:12:44,970 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:12:46,976 - INFO - Processing Question 16\n",
      "2024-11-06 05:12:46,979 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:12:48,984 - INFO - Processing Question 17\n",
      "2024-11-06 05:12:48,987 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:12:50,993 - INFO - Processing Question 18\n",
      "2024-11-06 05:12:50,996 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:12:53,002 - INFO - Processing Question 19\n",
      "2024-11-06 05:12:53,005 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:12:55,011 - INFO - Processing Question 20\n",
      "2024-11-06 05:12:55,014 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:12:57,021 - INFO - Processing Question 21\n",
      "2024-11-06 05:12:57,024 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:12:59,029 - INFO - Processing Question 22\n",
      "2024-11-06 05:12:59,033 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:13:01,039 - INFO - Processing Question 23\n",
      "2024-11-06 05:13:01,043 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:13:03,049 - INFO - Processing Question 24\n",
      "2024-11-06 05:13:03,053 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:13:05,058 - INFO - Processing Question 25\n",
      "2024-11-06 05:13:05,061 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:13:07,067 - INFO - Processing Question 26\n",
      "2024-11-06 05:13:07,070 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:13:09,076 - INFO - Processing Question 27\n",
      "2024-11-06 05:13:09,079 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:13:11,084 - INFO - Processing Question 28\n",
      "2024-11-06 05:13:11,087 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:13:13,093 - INFO - Processing Question 29\n",
      "2024-11-06 05:13:13,096 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:13:15,101 - INFO - Processing Question 30\n",
      "2024-11-06 05:13:15,104 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:13:17,109 - INFO - Processing Question 31\n",
      "2024-11-06 05:13:17,112 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:13:19,117 - INFO - Processing Question 32\n",
      "2024-11-06 05:13:19,120 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:13:21,126 - INFO - Processing Question 33\n",
      "2024-11-06 05:13:21,129 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:13:23,134 - INFO - Processing Question 34\n",
      "2024-11-06 05:13:23,137 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:13:25,143 - INFO - Processing Question 35\n",
      "2024-11-06 05:13:25,145 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:13:27,151 - INFO - Processing Question 36\n",
      "2024-11-06 05:13:27,154 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:13:29,160 - INFO - Processing Question 37\n",
      "2024-11-06 05:13:29,163 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:13:31,169 - INFO - Processing Question 38\n",
      "2024-11-06 05:13:31,172 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:13:33,177 - INFO - Processing Question 39\n",
      "2024-11-06 05:13:33,180 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:13:35,185 - INFO - Processing Question 40\n",
      "2024-11-06 05:13:35,188 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:13:37,194 - INFO - Processing Question 41\n",
      "2024-11-06 05:13:37,197 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:13:39,203 - INFO - Processing Question 42\n",
      "2024-11-06 05:13:39,206 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:13:41,212 - INFO - Processing Question 43\n",
      "2024-11-06 05:13:41,215 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:13:43,222 - INFO - Processing Question 44\n",
      "2024-11-06 05:13:43,224 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:13:45,230 - INFO - Processing Question 45\n",
      "2024-11-06 05:13:45,233 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:13:47,240 - INFO - Processing Question 46\n",
      "2024-11-06 05:13:47,242 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:13:49,248 - INFO - Processing Question 47\n",
      "2024-11-06 05:13:49,251 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:13:51,257 - INFO - Processing Question 48\n",
      "2024-11-06 05:13:51,260 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:13:53,266 - INFO - Processing Question 49\n",
      "2024-11-06 05:13:53,269 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:13:55,275 - INFO - Processing Question 50\n",
      "2024-11-06 05:13:55,278 - ERROR - Error querying model hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:13:57,285 - INFO - Stopped Ollama model\n",
      "2024-11-06 05:14:02,286 - INFO - Starting evaluation for model: hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M\n",
      "2024-11-06 05:14:12,288 - INFO - Started model: hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M\n",
      "2024-11-06 05:14:12,289 - INFO - Processing Question 1\n",
      "2024-11-06 05:14:13,358 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:14:15,364 - INFO - Processing Question 2\n",
      "2024-11-06 05:14:17,411 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:14:19,418 - INFO - Processing Question 3\n",
      "2024-11-06 05:14:21,316 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:14:23,322 - INFO - Processing Question 4\n",
      "2024-11-06 05:14:26,597 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:14:28,604 - INFO - Processing Question 5\n",
      "2024-11-06 05:14:31,875 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:14:33,882 - INFO - Processing Question 6\n",
      "2024-11-06 05:14:37,236 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:14:39,243 - INFO - Processing Question 7\n",
      "2024-11-06 05:14:42,569 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:14:44,575 - INFO - Processing Question 8\n",
      "2024-11-06 05:14:47,899 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:14:49,905 - INFO - Processing Question 9\n",
      "2024-11-06 05:14:53,207 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:14:55,214 - INFO - Processing Question 10\n",
      "2024-11-06 05:14:58,235 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:15:00,242 - INFO - Processing Question 11\n",
      "2024-11-06 05:15:03,535 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:15:05,540 - INFO - Processing Question 12\n",
      "2024-11-06 05:15:08,832 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:15:10,838 - INFO - Processing Question 13\n",
      "2024-11-06 05:15:14,920 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:15:16,926 - INFO - Processing Question 14\n",
      "2024-11-06 05:15:20,764 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:15:22,770 - INFO - Processing Question 15\n",
      "2024-11-06 05:15:25,919 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:15:27,926 - INFO - Processing Question 16\n",
      "2024-11-06 05:15:31,084 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:15:33,091 - INFO - Processing Question 17\n",
      "2024-11-06 05:15:36,245 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:15:38,251 - INFO - Processing Question 18\n",
      "2024-11-06 05:15:41,427 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:15:43,433 - INFO - Processing Question 19\n",
      "2024-11-06 05:15:46,407 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:15:48,413 - INFO - Processing Question 20\n",
      "2024-11-06 05:15:51,896 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:15:53,902 - INFO - Processing Question 21\n",
      "2024-11-06 05:15:57,058 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:15:59,064 - INFO - Processing Question 22\n",
      "2024-11-06 05:16:02,328 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:16:04,334 - INFO - Processing Question 23\n",
      "2024-11-06 05:16:07,561 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:16:09,567 - INFO - Processing Question 24\n",
      "2024-11-06 05:16:12,763 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:16:14,769 - INFO - Processing Question 25\n",
      "2024-11-06 05:16:18,045 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:16:20,051 - INFO - Processing Question 26\n",
      "2024-11-06 05:16:23,261 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:16:25,268 - INFO - Processing Question 27\n",
      "2024-11-06 05:16:28,398 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:16:30,404 - INFO - Processing Question 28\n",
      "2024-11-06 05:16:33,550 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:16:35,556 - INFO - Processing Question 29\n",
      "2024-11-06 05:16:38,703 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:16:40,709 - INFO - Processing Question 30\n",
      "2024-11-06 05:16:43,949 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:16:45,956 - INFO - Processing Question 31\n",
      "2024-11-06 05:16:49,278 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:16:51,284 - INFO - Processing Question 32\n",
      "2024-11-06 05:16:54,467 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:16:56,475 - INFO - Processing Question 33\n",
      "2024-11-06 05:17:00,326 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:17:02,333 - INFO - Processing Question 34\n",
      "2024-11-06 05:17:04,852 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:17:06,858 - INFO - Processing Question 35\n",
      "2024-11-06 05:17:10,058 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:17:12,064 - INFO - Processing Question 36\n",
      "2024-11-06 05:17:15,255 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:17:17,261 - INFO - Processing Question 37\n",
      "2024-11-06 05:17:20,430 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:17:22,436 - INFO - Processing Question 38\n",
      "2024-11-06 05:17:25,644 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:17:27,650 - INFO - Processing Question 39\n",
      "2024-11-06 05:17:30,774 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:17:32,780 - INFO - Processing Question 40\n",
      "2024-11-06 05:17:35,923 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:17:37,929 - INFO - Processing Question 41\n",
      "2024-11-06 05:17:41,077 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:17:43,083 - INFO - Processing Question 42\n",
      "2024-11-06 05:17:45,888 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:17:47,894 - INFO - Processing Question 43\n",
      "2024-11-06 05:17:51,361 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:17:53,367 - INFO - Processing Question 44\n",
      "2024-11-06 05:17:56,491 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:17:58,497 - INFO - Processing Question 45\n",
      "2024-11-06 05:18:01,722 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:18:03,729 - INFO - Processing Question 46\n",
      "2024-11-06 05:18:06,928 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:18:08,934 - INFO - Processing Question 47\n",
      "2024-11-06 05:18:12,092 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:18:14,098 - INFO - Processing Question 48\n",
      "2024-11-06 05:18:17,272 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:18:19,278 - INFO - Processing Question 49\n",
      "2024-11-06 05:18:22,421 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:18:24,427 - INFO - Processing Question 50\n",
      "2024-11-06 05:18:27,576 - ERROR - Error querying model hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M: 500 Server Error: Internal Server Error for url: http://localhost:11434/api/generate\n",
      "2024-11-06 05:18:29,583 - INFO - Stopped Ollama model\n",
      "2024-11-06 05:18:34,589 - INFO - Results saved to /home/ubuntu/quantumLeap/data/eval_for_base_model_selection/final/final_results_20241106_104834.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from typing import List, Dict\n",
    "import subprocess\n",
    "import signal\n",
    "import sys\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# Configure logging\n",
    "ist = pytz.timezone('Asia/Kolkata')\n",
    "ist_time = datetime.now(ist)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(f'llm_evaluation_{ist_time.strftime(\"%Y%m%d_%H%M%S\")}.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Constants\n",
    "OLLAMA_API_URL = \"http://localhost:11434/api/generate\"\n",
    "MODELS = [\n",
    "    # \"hf.co/bartowski/Qwen2.5-7B-Instruct-GGUF:Q5_K_L\",\n",
    "    # \"hf.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF:Q5_K_L\",\n",
    "    # \"hf.co/bartowski/Llama-3.2-3B-Instruct-GGUF:F16\",\n",
    "    # \"hf.co/bartowski/Llama-3.2-1B-Instruct-GGUF:F16\",\n",
    "    # \"hf.co/bartowski/Qwen2.5-14B-Instruct-GGUF:Q2_K\",\n",
    "    # \"hf.co/bartowski/Qwen2.5-3B-Instruct-GGUF:F16\",\n",
    "    # \"hf.co/bartowski/Qwen2.5-1.5B-Instruct-GGUF:F16\",\n",
    "    \"hf.co/bartowski/Phi-3-medium-128k-instruct-GGUF:Q3_K_S\",\n",
    "    \"hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q4_K_M\",\n",
    "]\n",
    "\n",
    "def load_questions() -> pd.DataFrame:\n",
    "    \"\"\"Load questions from CSV file.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv('/home/ubuntu/quantumLeap/quantumEval_claude.csv')\n",
    "        logging.info(f\"Successfully loaded {len(df)} questions from CSV\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading questions: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "def start_ollama_model(model_name: str) -> subprocess.Popen:\n",
    "    \"\"\"Start an Ollama model.\"\"\"\n",
    "    try:\n",
    "        process = subprocess.Popen(\n",
    "            ['ollama', 'run', model_name],\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE\n",
    "        )\n",
    "        time.sleep(10)  # Wait for model to initialize\n",
    "        logging.info(f\"Started model: {model_name}\")\n",
    "        return process\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error starting model {model_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "def stop_ollama_model(process: subprocess.Popen):\n",
    "    \"\"\"Stop the Ollama model process.\"\"\"\n",
    "    if process:\n",
    "        process.send_signal(signal.SIGTERM)\n",
    "        process.wait()\n",
    "        logging.info(\"Stopped Ollama model\")\n",
    "\n",
    "def query_model(question: str, model_name: str) -> str:\n",
    "    \"\"\"Query the model and get response.\"\"\"\n",
    "    prompt = f\"Please answer the following question about Clotaire Rapaille's Culture Code methodology:\\n\\n{question}\\n\\nProvide a clear and concise answer based on Rapaille's work.\"\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(OLLAMA_API_URL, json=payload)\n",
    "        response.raise_for_status()\n",
    "        return response.json()['response']\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error querying model {model_name}: {e}\")\n",
    "        return f\"ERROR: {str(e)}\"\n",
    "\n",
    "def evaluate_models(questions_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Evaluate all models on all questions.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for model in MODELS:\n",
    "        logging.info(f\"Starting evaluation for model: {model}\")\n",
    "        \n",
    "        # Start the model\n",
    "        process = start_ollama_model(model)\n",
    "        if not process:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            for _, row in questions_df.iterrows():\n",
    "                logging.info(f\"Processing Question {row['Question Number']}\")\n",
    "                \n",
    "                response = query_model(row['Question Text'], model)\n",
    "                \n",
    "                result = {\n",
    "                    'Question Number': row['Question Number'],\n",
    "                    'Attribute': row['Attribute'],\n",
    "                    'Expertise Level': row['Expertise Level'],\n",
    "                    'Question Text': row['Question Text'],\n",
    "                    'LLM Name': model,\n",
    "                    'Model Response': response,\n",
    "                    'Score': '',  # To be filled later\n",
    "                    'Explanation': ''  # To be filled later\n",
    "                }\n",
    "                results.append(result)\n",
    "                \n",
    "                # Save intermediate results with IST timestamp\n",
    "                ist_time = datetime.now(ist)\n",
    "                pd.DataFrame(results).to_csv(\n",
    "                    f'/home/ubuntu/quantumLeap/data/eval_for_base_model_selection/temp/results_{ist_time.strftime(\"%Y%m%d_%H%M%S\")}.csv',\n",
    "                    index=False\n",
    "                )\n",
    "                \n",
    "                time.sleep(2)  # Brief pause between questions\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during evaluation of model {model}: {e}\")\n",
    "        finally:\n",
    "            stop_ollama_model(process)\n",
    "            time.sleep(5)  # Wait before starting next model\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function.\"\"\"\n",
    "    try:\n",
    "        # Load questions\n",
    "        questions_df = load_questions()\n",
    "        \n",
    "        # Run evaluations\n",
    "        results_df = evaluate_models(questions_df)\n",
    "        \n",
    "        # Save final results with IST timestamp\n",
    "        ist_time = datetime.now(ist)\n",
    "        output_file = f'/home/ubuntu/quantumLeap/data/eval_for_base_model_selection/final/final_results_{ist_time.strftime(\"%Y%m%d_%H%M%S\")}.csv'\n",
    "        results_df.to_csv(output_file, index=False)\n",
    "        logging.info(f\"Results saved to {output_file}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in main execution: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question Number</th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Expertise Level</th>\n",
       "      <th>LLM Name</th>\n",
       "      <th>LLM Name.1</th>\n",
       "      <th>Model Response</th>\n",
       "      <th>Score</th>\n",
       "      <th>Explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>Beginner</td>\n",
       "      <td>What is the basic definition of a 'Culture Cod...</td>\n",
       "      <td>hf.co/bartowski/Phi-3-medium-128k-instruct-GGU...</td>\n",
       "      <td>The 'Culture Code,' as defined by Clotaire Rap...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>Beginner</td>\n",
       "      <td>What was Rapaille's key insight about how cult...</td>\n",
       "      <td>hf.co/bartowski/Phi-3-medium-128k-instruct-GGU...</td>\n",
       "      <td>Rapaille's key insight is that cultural imprin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Relevance</td>\n",
       "      <td>Beginner</td>\n",
       "      <td>How did Rapaille use his Culture Code methodol...</td>\n",
       "      <td>hf.co/bartowski/Phi-3-medium-128k-instruct-GGU...</td>\n",
       "      <td>Clotaire Rapaille used his Culture Code method...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Relevance</td>\n",
       "      <td>Beginner</td>\n",
       "      <td>Why did Rapaille conduct his research sessions...</td>\n",
       "      <td>hf.co/bartowski/Phi-3-medium-128k-instruct-GGU...</td>\n",
       "      <td>Clotaire Rapaille conducted his research sessi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Depth</td>\n",
       "      <td>Beginner</td>\n",
       "      <td>Explain Rapaille's concept of 'imprints' and h...</td>\n",
       "      <td>hf.co/bartowski/Phi-3-medium-128k-instruct-GGU...</td>\n",
       "      <td>Clotaire Rapaille's concept of 'imprints', als...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Question Number  Attribute Expertise Level  \\\n",
       "0                1   Accuracy        Beginner   \n",
       "1                2   Accuracy        Beginner   \n",
       "2                3  Relevance        Beginner   \n",
       "3                4  Relevance        Beginner   \n",
       "4                5      Depth        Beginner   \n",
       "\n",
       "                                            LLM Name  \\\n",
       "0  What is the basic definition of a 'Culture Cod...   \n",
       "1  What was Rapaille's key insight about how cult...   \n",
       "2  How did Rapaille use his Culture Code methodol...   \n",
       "3  Why did Rapaille conduct his research sessions...   \n",
       "4  Explain Rapaille's concept of 'imprints' and h...   \n",
       "\n",
       "                                          LLM Name.1  \\\n",
       "0  hf.co/bartowski/Phi-3-medium-128k-instruct-GGU...   \n",
       "1  hf.co/bartowski/Phi-3-medium-128k-instruct-GGU...   \n",
       "2  hf.co/bartowski/Phi-3-medium-128k-instruct-GGU...   \n",
       "3  hf.co/bartowski/Phi-3-medium-128k-instruct-GGU...   \n",
       "4  hf.co/bartowski/Phi-3-medium-128k-instruct-GGU...   \n",
       "\n",
       "                                      Model Response  Score  Explanation  \n",
       "0  The 'Culture Code,' as defined by Clotaire Rap...    NaN          NaN  \n",
       "1  Rapaille's key insight is that cultural imprin...    NaN          NaN  \n",
       "2  Clotaire Rapaille used his Culture Code method...    NaN          NaN  \n",
       "3  Clotaire Rapaille conducted his research sessi...    NaN          NaN  \n",
       "4  Clotaire Rapaille's concept of 'imprints', als...    NaN          NaN  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/home/ubuntu/quantumLeap/data/eval_for_base_model_selection/final/final_results_20241106_104834_v2.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###\n",
      " Theory\n",
      ":\n",
      " The\n",
      " Cultural\n",
      " AI\n",
      " Nexus\n",
      " (\n",
      "CAN\n",
      ")\n",
      "\n",
      "\n",
      "####\n",
      " Introduction\n",
      "\n",
      "\n",
      "The\n",
      " Cultural\n",
      " AI\n",
      " Nexus\n",
      " (\n",
      "CAN\n",
      ")\n",
      " is\n",
      " a\n",
      " groundbreaking\n",
      " theory\n",
      " that\n",
      " integrates\n",
      " Dr\n",
      ".\n",
      " Cl\n",
      "ota\n",
      "ire\n",
      " Rap\n",
      "aille\n",
      "'s\n",
      " \"\n",
      "The\n",
      " Culture\n",
      " Code\n",
      "\"\n",
      " with\n",
      " advanced\n",
      " artificial\n",
      " intelligence\n",
      " (\n",
      "AI\n",
      ")\n",
      " and\n",
      " machine\n",
      " learning\n",
      " (\n",
      "ML\n",
      ")\n",
      " technologies\n",
      " to\n",
      " predict\n",
      " and\n",
      " influence\n",
      " consumer\n",
      " behavior\n",
      " in\n",
      " an\n",
      " era\n",
      " of\n",
      " globalization\n",
      " and\n",
      " cultural\n",
      " hybrid\n",
      "ization\n",
      ".\n",
      " This\n",
      " theory\n",
      " lever\n",
      "ages\n",
      " the\n",
      " deep\n",
      " cultural\n",
      " insights\n",
      " provided\n",
      " by\n",
      " Rap\n",
      "aille\n",
      "’s\n",
      " work\n",
      " and\n",
      " combines\n",
      " them\n",
      " with\n",
      " the\n",
      " computational\n",
      " power\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Check if the request was successful\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Process each line in the streaming response\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# Decode the JSON object\u001b[39;49;00m\n",
      "File \u001b[0;32m~/miniconda/envs/ql/lib/python3.12/site-packages/requests/models.py:869\u001b[0m, in \u001b[0;36mResponse.iter_lines\u001b[0;34m(self, chunk_size, decode_unicode, delimiter)\u001b[0m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Iterates over the response data, one line at a time.  When\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;124;03mstream=True is set on the request, this avoids reading the\u001b[39;00m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;124;03mcontent at once into memory for large responses.\u001b[39;00m\n\u001b[1;32m    863\u001b[0m \n\u001b[1;32m    864\u001b[0m \u001b[38;5;124;03m.. note:: This method is not reentrant safe.\u001b[39;00m\n\u001b[1;32m    865\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    867\u001b[0m pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 869\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_unicode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_unicode\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpending\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpending\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/ql/lib/python3.12/site-packages/requests/models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/miniconda/envs/ql/lib/python3.12/site-packages/urllib3/response.py:1057\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;124;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;124;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;124;03m    'content-encoding' header.\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_chunked_reads():\n\u001b[0;32m-> 1057\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_chunked(amt, decode_content\u001b[38;5;241m=\u001b[39mdecode_content)\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1059\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda/envs/ql/lib/python3.12/site-packages/urllib3/response.py:1206\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1203\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1206\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_chunk_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1207\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1208\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/ql/lib/python3.12/site-packages/urllib3/response.py:1125\u001b[0m, in \u001b[0;36mHTTPResponse._update_chunk_length\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1125\u001b[0m line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m   1126\u001b[0m line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda/envs/ql/lib/python3.12/socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Define the API endpoint\n",
    "url = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "# Set the headers\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "# Define the payload\n",
    "payload = {\n",
    "    \"model\": \"hf.co/RichardErkhov/Qwen_-_Qwen2.5-72B-Instruct-gguf:Q3_K\",  # Replace with your model name\n",
    "    \"prompt\": \"Envision a groundbreaking theory that unites Dr. Clotaire Rapaille's 'The Culture Code' with advanced artificial intelligence and machine learning technologies to predict and influence consumer behavior in the era of globalization and cultural hybridization. Provide a comprehensive explanation of your proposed theory, detailing how it integrates cultural codes with AI, the potential impact on global marketing strategies, and how it could transform consumer research methodologies. Ensure your response is accurate, relevant, deep, clear, and original.\",\n",
    "}\n",
    "\n",
    "# Send the POST request\n",
    "response = requests.post(url, headers=headers, data=json.dumps(payload), stream=True)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Process each line in the streaming response\n",
    "    for line in response.iter_lines():\n",
    "        if line:\n",
    "            try:\n",
    "                # Decode the JSON object\n",
    "                result = json.loads(line.decode('utf-8'))\n",
    "                # Access the generated text\n",
    "                generated_text = result.get(\"response\", \"\")\n",
    "                print(generated_text)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"JSON decode error: {e}\")\n",
    "else:\n",
    "    print(f\"Request failed with status code {response.status_code}: {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
