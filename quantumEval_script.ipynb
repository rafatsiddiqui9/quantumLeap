{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from typing import List, Dict\n",
    "import subprocess\n",
    "import signal\n",
    "import sys\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(f'llm_evaluation_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Constants\n",
    "OLLAMA_API_URL = \"http://localhost:11434/api/generate\"\n",
    "MODELS = [\n",
    "    \"hf.co/bartowski/Qwen2.5-7B-Instruct-GGUF:Q5_K_L\",\n",
    "    \"hf.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF:Q5_K_L\",\n",
    "    \"hf.co/bartowski/Llama-3.2-3B-Instruct-GGUF:F16\",\n",
    "    \"hf.co/bartowski/Llama-3.2-1B-Instruct-GGUF:F16\",\n",
    "    \"hf.co/bartowski/Qwen2.5-14B-Instruct-GGUF:Q2_K\",\n",
    "    \"hf.co/bartowski/Qwen2.5-3B-Instruct-GGUF:F16\",\n",
    "    \"hf.co/bartowski/Qwen2.5-1.5B-Instruct-GGUF:F16\",\n",
    "    \"hf.co/bartowski/Phi-3-medium-128k-instruct-GGUF:Q3_K_S\",\n",
    "    \"hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q4_K_M\",\n",
    "    \"hf.co/mradermacher/gemma-2-9b-it-SimPO-GGUF:F16\",\n",
    "    \"hf.co/RichardErkhov/princeton-nlp_-_gemma-2-9b-it-SimPO-gguf:Q8_0\",\n",
    "    \"hf.co/DevQuasar/ai21labs.AI21-Jamba-1.5-Mini-GGUF:Q4_K_M\"\n",
    "]\n",
    "\n",
    "def load_questions() -> pd.DataFrame:\n",
    "    \"\"\"Load questions from CSV file.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv('/home/ubuntu/quantumLeap/quantumEval_claude.csv')\n",
    "        logging.info(f\"Successfully loaded {len(df)} questions from CSV\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading questions: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "def start_ollama_model(model_name: str) -> subprocess.Popen:\n",
    "    \"\"\"Start an Ollama model.\"\"\"\n",
    "    try:\n",
    "        process = subprocess.Popen(\n",
    "            ['ollama', 'run', model_name],\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE\n",
    "        )\n",
    "        time.sleep(10)  # Wait for model to initialize\n",
    "        logging.info(f\"Started model: {model_name}\")\n",
    "        return process\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error starting model {model_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "def stop_ollama_model(process: subprocess.Popen):\n",
    "    \"\"\"Stop the Ollama model process.\"\"\"\n",
    "    if process:\n",
    "        process.send_signal(signal.SIGTERM)\n",
    "        process.wait()\n",
    "        logging.info(\"Stopped Ollama model\")\n",
    "\n",
    "def query_model(question: str, model_name: str) -> str:\n",
    "    \"\"\"Query the model and get response.\"\"\"\n",
    "    prompt = f\"Please answer the following question about Clotaire Rapaille's Culture Code methodology:\\n\\n{question}\\n\\nProvide a clear and concise answer based on Rapaille's work.\"\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(OLLAMA_API_URL, json=payload)\n",
    "        response.raise_for_status()\n",
    "        return response.json()['response']\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error querying model {model_name}: {e}\")\n",
    "        return f\"ERROR: {str(e)}\"\n",
    "\n",
    "def evaluate_models(questions_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Evaluate all models on all questions.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for model in MODELS:\n",
    "        logging.info(f\"Starting evaluation for model: {model}\")\n",
    "        \n",
    "        # Start the model\n",
    "        process = start_ollama_model(model)\n",
    "        if not process:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            for _, row in questions_df.iterrows():\n",
    "                logging.info(f\"Processing Question {row['Question Number']}\")\n",
    "                \n",
    "                response = query_model(row['Question Text'], model)\n",
    "                \n",
    "                result = {\n",
    "                    'Question Number': row['Question Number'],\n",
    "                    'Attribute': row['Attribute'],\n",
    "                    'Expertise Level': row['Expertise Level'],\n",
    "                    'Question Text': row['Question Text'],\n",
    "                    'LLM Name': model,\n",
    "                    'Model Response': response,\n",
    "                    'Score': '',  # To be filled later\n",
    "                    'Explanation': ''  # To be filled later\n",
    "                }\n",
    "                results.append(result)\n",
    "                \n",
    "                # Save intermediate results\n",
    "                pd.DataFrame(results).to_csv(\n",
    "                    f'results_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.csv',\n",
    "                    index=False\n",
    "                )\n",
    "                \n",
    "                time.sleep(2)  # Brief pause between questions\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during evaluation of model {model}: {e}\")\n",
    "        finally:\n",
    "            stop_ollama_model(process)\n",
    "            time.sleep(5)  # Wait before starting next model\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function.\"\"\"\n",
    "    try:\n",
    "        # Load questions\n",
    "        questions_df = load_questions()\n",
    "        \n",
    "        # Run evaluations\n",
    "        results_df = evaluate_models(questions_df)\n",
    "        \n",
    "        # Save final results\n",
    "        output_file = f'final_results_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.csv'\n",
    "        results_df.to_csv(output_file, index=False)\n",
    "        logging.info(f\"Results saved to {output_file}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in main execution: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
